{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar y descomprimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar los siguientes módulos.\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descomprimir el dataset original.\n",
    "local_zip = './dataset_original.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('dataset_original')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De JSON a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecutar dos veces, una para test y otra para train.\n",
    "type_file = 'train'\n",
    "path = './cv_train.json'\n",
    "data_file = open(path)\n",
    "data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir la estructura del JSON de origen y de la variables relevantes:\n",
    "#1. clase.\n",
    "#2. bounding box (x inicial, y inicial, x final, y final).\n",
    "#3. bncho y alto de la imagen.\n",
    "#4. nombre del archivo.\n",
    "csv_list = []\n",
    "\n",
    "for classification in data:\n",
    "  width, height = classification['width'], classification['height']\n",
    "  image = classification['image']\n",
    "  for item in classification['tags']:\n",
    "    name = item['name']\n",
    "    xmin = item['pos']['x']\n",
    "    ymin = item['pos']['y']\n",
    "    xmax = item['pos']['x'] + item['pos']['w']\n",
    "    ymax = item['pos']['y'] + item['pos']['h']\n",
    "\n",
    "    value = (image, width, height, name, xmin, ymin, xmax, ymax)\n",
    "    csv_list.append(value)\n",
    "\n",
    "#almacenar en CSV con el nombre de las siguientes columnas.\n",
    "column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "csv_df = pd.DataFrame(csv_list, columns = column_name)\n",
    "\n",
    "#convertir el dataframe a CSV.\n",
    "csv_df.to_csv('./{}_labels.csv'.format(type_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De CSV a TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar la librería Object Detection de TensorFlow.\n",
    "\n",
    "En la terminal WSL:<br>\n",
    "cd cv-project<br>\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "cd models<br>\n",
    "git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
    "\n",
    "sudo apt-get install protobuf-compiler python-pil python-lxml python-tk<br>\n",
    "pip install Cython contextlib2 pillow lxml matplotlib<br>\n",
    "pip install pycocotools\n",
    "\n",
    "cd research<br>\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/personal/Desktop/workspace/cv-project/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd ../models/research\n",
    "os.environ['PYTHONPATH'] = '../models/research/:../models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /mnt/c/Users/personal/Desktop/workspace/cv-project/models/research/train.record\n"
     ]
    }
   ],
   "source": [
    "#tomar el script base y modificar según el proyecto.\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../../models/research\")\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'auto': \n",
    "      return 1\n",
    "    elif row_label == 'moto':\n",
    "      return 2\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "#ejecutar dos veces, una para test y otra para train.\n",
    "output_path = 'train.record' \n",
    "image_dir = '/mnt/c/Users/personal/Desktop/workspace/cv-project/p1_obtener_y_procesar_datos/dataset_original/dataset_original'\n",
    "csv_input = '/mnt/c/Users/personal/Desktop/workspace/cv-project/p1_obtener_y_procesar_datos/train_labels.csv'\n",
    "#solo acá no me acepta las rutas relativas, por alguna razón.\n",
    "\n",
    "writer = tf.io.TFRecordWriter(output_path)\n",
    "path = os.path.join(image_dir)\n",
    "examples = pd.read_csv(csv_input)\n",
    "grouped = split(examples, 'filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group, path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "output_path = os.path.join(os.getcwd(), output_path)\n",
    "print('Successfully created the TFRecords: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto termina con train.record y test.record en models/research. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f37e4b51f1b7e8b5084d7006079a4e1c09d50ce66974673d0c56e69434aefbea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
